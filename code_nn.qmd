---
title: "sl-project"
format: html
editor: visual
---

```{r}
library(reticulate)
use_condaenv("keras3", required = TRUE)
```

```{r}
set.seed(123)

library(DBI)
library(RSQLite)
library(tidyverse)
library(lubridate)
library(caret)
library(keras3)
library(Metrics)
```

```{r}
#| echo: false
con <- dbConnect(RSQLite::SQLite(), dbname = "data/database.sqlite")
dbListTables(con)
df_player_raw <- dbGetQuery(con, "SELECT * FROM Player JOIN Player_Attributes USING (player_api_id)")

names(df_player_raw) <- make.unique(names(df_player_raw))
dbDisconnect(con)
```

```{r}

df_player<-df_player_raw%>%
  filter(complete.cases(.))%>%
  mutate(date=ymd_hms(date),
         birthday=ymd_hms(birthday),
         age=floor(time_length(interval(birthday, date),"years")))%>%
  select(-id,-id.1,-player_name, -player_fifa_api_id, -player_fifa_api_id.1, -weight, -height, -birthday, -date, -defensive_work_rate, -attacking_work_rate, -overall_rating)%>%
  filter(age>=16)

X<-model.matrix(potential~.,df_player)[,-1]
y<-df_player$potential

player_id <- df_player$player_api_id
X <- X[, colnames(X) != "player_api_id"]
```

```{r}
#| eval: false
# OUTER grouped 5-fold CV
dir.create("models_nn", showWarnings = FALSE)

## 5-fold, grouped by Player
outer_folds <- groupKFold(group = player_id, k = 5)

## Storage 
outer_results <- vector("list", 5)
best_params   <- vector("list", 5)
loss_log <- list()


## Checkpoint printer
loss_printer <- function(i, g, j) {
  callback_lambda(
    on_epoch_end = function(epoch, logs) {
      cat(sprintf(
        "Outer %d | Grid %d | Epoch %d | loss=%.4f | val=%.4f\n",
        i, g, epoch + 1,
        logs$loss,
        logs$val_loss
      ))
    }
  )
}

## Hyperparameter grid
grid <- crossing(
  nodes1 = c(128, 256),
  nodes2 = c(64, 128),
  nodes3 = c(32, 64),
  dropout1 = c(0.3, 0.4),
  dropout2 = c(0.2, 0.3),
  dropout3 = c(0.1, 0.2),
  lr_annealing = c(0.1, 0.5)
)

## L2 Regularizer 
l2_reg <- regularizer_l2(0.001)

##Model builder
build_and_fit <- function(X_train, y_train,
                          X_val, y_val,
                          nodes1, nodes2, nodes3,
                          dropout1, dropout2, dropout3,
                          lr_annealing,
                          i = NA, g = NA) {
  model <- keras_model_sequential() %>%
    layer_dense(nodes1, activation = "relu",
                input_shape = c(ncol(X_train)),
                kernel_regularizer = l2_reg) %>%
    layer_batch_normalization() %>%
    layer_dropout(dropout1) %>%
    
    layer_dense(nodes2, 
                activation = "relu",
                kernel_regularizer = l2_reg) %>%
    layer_batch_normalization() %>%
    layer_dropout(dropout2) %>%
    
    layer_dense(nodes3, 
                activation = "relu",
                kernel_regularizer = l2_reg) %>%
    layer_batch_normalization() %>%
    layer_dropout(dropout3) %>%
    
    layer_dense(1, activation="linear")

  model %>% compile(
    optimizer = optimizer_adam(),
    loss = "mean_squared_error"
  )

  history <- model %>% fit(
    X_train, y_train,
    epochs = 50,
    batch_size = 128,
    validation_data = list(X_val, y_val),
    callbacks = list(
      callback_early_stopping(
        patience = 5,
        restore_best_weights = TRUE
      ),
      callback_reduce_lr_on_plateau(
        factor = lr_annealing
      ),
      loss_printer(i, g, 1)
    ),
    verbose = 0
  )

  list(
    model = model,
    history = history,
    val_loss = min(history$metrics$val_loss)
  )
}


start_i <- 1

# OUTER LOOP over k-folds
for (i in start_i:length(outer_folds)) {

  cat("Outer fold:", i, "\n")

  train_idx <- outer_folds[[i]]
  test_idx  <- setdiff(seq_len(nrow(X)), train_idx)

  X_train <- X[train_idx, ]
  X_test  <- X[test_idx, ]
  y_train <- y[train_idx]
  y_test  <- y[test_idx]

  
  ## Fold-specific normalization
  preproc <- preProcess(X_train, method = c("center", "scale"))
  X_train_scaled <- predict(preproc, X_train)
  X_test_scaled  <- predict(preproc, X_test)
  
  ## Fold-specific validation-split
  groups_outer <- unique(player_id[train_idx])
  
  val_groups <- sample(
    groups_outer,
    size = ceiling(0.2 * length(groups_outer))
  )

  inner_val_idx <- which(player_id[train_idx] %in% val_groups)
  inner_train_idx <- setdiff(
    seq_len(nrow(X_train_scaled)),
    inner_val_idx
  )
  
  ## Grid Search
  
  ### Grid results tracker
  grid_results <- grid %>%
    mutate(val_loss = NA_real_)
  
  best_fit      <- NULL
  best_val_loss <- Inf
  
  ### Build and Fit model for each grid combination
  for (g in seq_len(nrow(grid))) {
    fit <- build_and_fit(
      X_train_scaled[inner_train_idx, ],
      y_train[inner_train_idx],
      X_train_scaled[inner_val_idx, ],
      y_train[inner_val_idx],
      grid$nodes1[g],
      grid$nodes2[g],
      grid$nodes3[g],
      grid$dropout1[g],
      grid$dropout2[g],
      grid$dropout3[g],
      grid$lr_annealing[g],
      i = i, g = g
    )
    
    #### Track validation loss for each grid combination
    grid_results$val_loss[g] <- fit$val_loss
    
    
    if (fit$val_loss < best_val_loss) {
      best_val_loss <- fit$val_loss
      best_fit <- fit
    }
    clear_session()
  }
  
  ### Select best hyperparameters
  best_row <- grid_results %>%
    arrange(val_loss) %>%
    slice(1)

  best_params[[i]] <- best_row
  
  loss_log[[paste0("fold_", i)]] <-
    tibble(
      Fold = i,
      epoch = seq_along(best_fit$history$metrics$val_loss),
      val_loss = best_fit$history$metrics$val_loss
    )
  
  
  ## Refit best model of the fold
  final_fit <- build_and_fit(
    X_train_scaled,
    y_train,
    X_train_scaled,
    y_train,   # dummy validation (not used due to early stopping patience)
    best_row$nodes1,
    best_row$nodes2,
    best_row$nodes3,
    best_row$dropout1,
    best_row$dropout2,
    best_row$dropout3,
    best_row$lr_annealing
  )
  model_nn <- final_fit$model
  
  ## Checkpoint-save fold model
  model_path<-sprintf("models_nn/nn_outer_fold_%d.keras", i)
  save_model(
    model_nn,
    filepath = model_path,
    overwrite = TRUE
  )
  
  ## Fold evaluation
  y_pred_train <- predict(model_nn, X_train_scaled)
  y_pred_test  <- predict(model_nn, X_test_scaled)

  outer_results[[i]] <- tibble(
    Fold = i,
    Train_MSE = mse(y_train, y_pred_train),
    Test_MSE  = mse(y_test, y_pred_test),
    Train_MAE = mae(y_train, y_pred_train),
    Test_MAE  = mae(y_test, y_pred_test)
  )

  clear_session()
} 

saveRDS(best_params, file = "models_nn/best_params.rds")
saveRDS(loss_log,   file = "models_nn/loss_log.rds")
```

```{r}
# Re-loading models 
n_folds <- 5
models <- vector("list", n_folds)

for (i in seq_len(n_folds)) {
  models[[i]] <- load_model(
    sprintf("models_nn/nn_outer_fold_%d.keras", i)
  )
}


# Inference Loop:
outer_results2 <- vector("list", length(models))

for (i in seq_along(models)) {

  model <- models[[i]]
  train_idx <- outer_folds[[i]]
  test_idx  <- setdiff(seq_len(nrow(X)), train_idx)

  X_train <- X[train_idx, ]
  X_test  <- X[test_idx, ]
  y_train <- y[train_idx]
  y_test  <- y[test_idx]

  
  ## Fold-specific normalization
  preproc <- preProcess(X_train, method = c("center", "scale"))
  X_train_scaled <- predict(preproc, X_train)
  X_test_scaled  <- predict(preproc, X_test)

  ## Fold evaluation
  y_pred_train <- as.numeric(predict(model, X_train_scaled))
  y_pred_test  <- as.numeric(predict(model, X_test_scaled))

  outer_results2[[i]] <- tibble(
    Fold = i,
    Train_MSE = mse(y_train, y_pred_train),
    Test_MSE  = mse(y_test, y_pred_test),
    Train_MAE = mae(y_train, y_pred_train),
    Test_MAE  = mae(y_test, y_pred_test)
  )
}


# Final summaries
cv_results <- bind_rows(outer_results2)
cv_results
cv_results %>%
  summarise(across(-Fold, mean))


saveRDS(cv_results, file = "models_nn/evaluation_metrics_nn.rds")
```

```{r}
player_names <- df_player_raw %>%
  select(player_api_id, player_name) %>%
  distinct(player_api_id, .keep_all = TRUE)

test_df <- df_player[test_idx, ] %>%
  mutate(
    y_true = y_test,
    y_pred = as.numeric(y_pred_test)
  ) %>%
  left_join(player_names, by = "player_api_id") %>%
  select(player_api_id, player_name, potential, y_true, y_pred, age)

```
